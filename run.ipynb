{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Useful imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_file):\n",
    "    \"\"\"load data.\"\"\"\n",
    "    data = np.genfromtxt(\n",
    "        path_file, delimiter=\",\", skip_header=1)\n",
    "    y = np.genfromtxt(\n",
    "        path_file, delimiter=\",\", skip_header=1, usecols=[1],dtype=str)\n",
    "    y[y=='b'] = -1\n",
    "    y[y=='s'] = 1\n",
    "    x = np.genfromtxt(\n",
    "        path_file, delimiter=\",\", skip_header=1, usecols=range(2,32))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data/'\n",
    "DATA_TEST = 'test.csv'\n",
    "DATA_TRAIN = 'train.csv'\n",
    "\n",
    "tx,y = load_data(DATA_FOLDER+DATA_TRAIN)\n",
    "tx_sub = np.genfromtxt(DATA_FOLDER+DATA_TEST, delimiter=\",\", skip_header=1, usecols=range(2,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data and manage outliers\n",
    "We set the outliers to the mean value of the feature (calculated without the outliers), so that they are set to 0 when the standardization is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_manage_outliers(x):\n",
    "    \"\"\"\n",
    "    set outliers to the mean value of the feature, then standardize the data\n",
    "    \n",
    "    Args:\n",
    "        x: numpy array of shape=(N,D)\n",
    "    Returns:\n",
    "        A numpy array of shape (N,D) with outliers set to the mean value of the features (axis 0)\n",
    "    \"\"\"\n",
    "    for j in range(x.shape[1]):\n",
    "        mean = np.mean(x[:,j][x[:,j]!=-999.0])\n",
    "        std = np.std(x[:,j][x[:,j]!=-999.0])\n",
    "        x[:,j][x[:,j]==-999.0] = mean\n",
    "        x[:,j] = (x[:,j]-mean)/std\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = standardize_manage_outliers(tx)\n",
    "tx_sub = standardize_manage_outliers(tx_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = 5\n",
    "tx_tr_aug = build_poly(tx_tr,degree=deg)\n",
    "tx_te_aug = build_poly(tx_te,degree=deg)\n",
    "tx_sub_aug = build_poly(tx_sub,degree=deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_fct = [i for i in range(6)]\n",
    "fct1 = lambda x:np.log(np.abs(x+1e-4))*x\n",
    "fct2 = lambda x:np.cos(x)/(np.abs(x)+1e-4)\n",
    "fct2_1 = lambda x:np.cos(x*2)/(np.abs(2*x)+1e-4)\n",
    "fct3 = lambda x:np.sin(x)\n",
    "fct3_1 = lambda x:np.sin(x*2)\n",
    "fct4 = lambda x: np.sin(np.exp(x))\n",
    "fct5 = lambda x:np.sinc(x)\n",
    "fct6 = lambda x:np.cos(x)/(1+np.exp(x))\n",
    "fct7 = lambda x:np.sin(x)/(1+np.exp(x))\n",
    "for fct in [fct2, fct2_1, fct3, fct3_1, fct5, fct6]:\n",
    "    tx_tr_aug = add_fct(tx_tr, tx_tr_aug, features=features_to_fct, fct=fct)\n",
    "    tx_te_aug = add_fct(tx_te, tx_te_aug, features=features_to_fct, fct=fct)\n",
    "    tx_sub_aug = add_fct(tx_sub, tx_sub_aug, features=features_to_fct, fct=fct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(y,seuil=0):\n",
    "    \"\"\"\n",
    "    projects y on {-1,1}\n",
    "    \n",
    "    Args:\n",
    "        y: numpy array of shape=(N,). Predictions of the model.\n",
    "        seuil: float. Threshold for the projection.\n",
    "    Returns:\n",
    "        y: projection of the input y on {-1,1} according to the threshold\n",
    "    \"\"\"\n",
    "    y[y<seuil] = -1\n",
    "    y[y>=seuil] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,loss = ridge_regression(y_tr,tx_tr_aug,lambda_=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(w,x_test,y_test,seuil=0):\n",
    "    '''\n",
    "    Function to test the accuracy of the model\n",
    "    \n",
    "    Args:\n",
    "        w: numpy array of shape=(D,). Weights of the model.\n",
    "        x_test: numpy array of shape=(N,D). Test data.\n",
    "        y_test: numpy array of shape=(N,). Test labels.\n",
    "    Returns:\n",
    "        y: numpy array of shape=(N,). Projection of y on {-1,1} (see the classify function)\n",
    "        accuracy: float. Number of good predicted labels divided by total number of prediction (N).\n",
    "    '''\n",
    "    y = classify(np.dot(x_test,w),seuil)\n",
    "    diff= (y_test == classify(y))\n",
    "    accuracy = diff.sum()/len(diff)\n",
    "    return y,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  1., -1., ..., -1.,  1., -1.]), 0.82142)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_model(w,tx_te_aug,y_te,seuil=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_pred(y):\n",
    "    '''\n",
    "    Saves the predicted labels y in the appropriate format.\n",
    "    \n",
    "    Args:\n",
    "        y: numpy array of shape=(N,). Predicted labels.\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    ids = np.genfromtxt(DATA_FOLDER+DATA_TEST, delimiter=\",\", skip_header=1,usecols=[0])\n",
    "    to_submit = np.zeros((y_sub.shape[0],2))\n",
    "    to_submit[:,0] = ids\n",
    "    to_submit[:,1] = y\n",
    "    np.savetxt('submission.csv', to_submit,delimiter=',',header='Id,Prediction',comments='')\n",
    "    print('Successfully saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1.,  1., ...,  1., -1., -1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub = classify(np.dot(tx_sub_aug,w))\n",
    "y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved\n"
     ]
    }
   ],
   "source": [
    "submit_pred(y_sub)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
